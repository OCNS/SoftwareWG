<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>INCF/OCNS Software WG - Brian2CUDA</title><link href="https://ocns.github.io/SoftwareWG/" rel="alternate"></link><link href="https://ocns.github.io/SoftwareWG/feeds/tags/brian2cuda.atom.xml" rel="self"></link><id>https://ocns.github.io/SoftwareWG/</id><updated>2022-10-18T10:38:20+01:00</updated><subtitle>The INCF/OCNS Software Working Group</subtitle><entry><title>Dev session: Denis Alevi:Â Brian2CUDA</title><link href="https://ocns.github.io/SoftwareWG/2022/10/18/dev-session-denis-alevi-brian2cuda.html" rel="alternate"></link><published>2022-10-18T10:38:20+01:00</published><updated>2022-10-18T10:38:20+01:00</updated><author><name>Ankur Sinha</name></author><id>tag:ocns.github.io,2022-10-18:/SoftwareWG/2022/10/18/dev-session-denis-alevi-brian2cuda.html</id><summary type="html">&lt;p class="first last"&gt;&lt;a class="reference external" href="https://www.sprekelerlab.org/denis/"&gt;Denis Alevi&lt;/a&gt; will introduce the &lt;a class="reference external" href="https://brian2cuda.readthedocs.io/en/latest/"&gt;Brian2CUDA&lt;/a&gt; tool in this session, and discuss its development. We will also have a discussion on &lt;span class="caps"&gt;GPU&lt;/span&gt; based simulation in neuroscience after the&amp;nbsp;presentation.&lt;/p&gt;
</summary><content type="html">&lt;p&gt;&lt;a class="reference external" href="https://www.sprekelerlab.org/denis/"&gt;Denis Alevi&lt;/a&gt; will introduce the &lt;a class="reference external" href="https://brian2cuda.readthedocs.io/en/latest/"&gt;Brian2CUDA&lt;/a&gt; tool in this session, and discuss its development. We will also have a discussion on &lt;span class="caps"&gt;GPU&lt;/span&gt; based simulation in neuroscience after the&amp;nbsp;presentation.&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Date: Thursday, November 3, 2022, 1600 &lt;span class="caps"&gt;UTC&lt;/span&gt; (Click &lt;a class="reference external" href="https://www.timeanddate.com/worldclock/fixedtime.html?msg=Dev+session%3A+Denis+Alevi+Brian2CUDA&amp;amp;iso=20221103T16&amp;amp;p1=136&amp;amp;ah=1"&gt;here&lt;/a&gt; to see your local&amp;nbsp;time).&lt;/li&gt;
&lt;li&gt;Location (Zoom): &lt;a class="reference external" href="https://ucl.zoom.us/j/95692778384?pwd=VldIQ3hPTU1zczNpYjQxSSt4Z25xdz09"&gt;Link&lt;/a&gt; (Zoom login&amp;nbsp;required)&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="/extras/ics/20221103-dev-session-denis-alevi-brian2cuda.ics"&gt;Click here to download the calendar invite to add this meeting your&amp;nbsp;calendar&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The abstract for the talk is&amp;nbsp;below:&lt;/p&gt;
&lt;p&gt;Graphics processing units (GPUs) are widely available and have been used with
great success to accelerate scientific computing in the last decade. These
advances, however, are often not available to researchers interested in
simulating spiking neural networks, but lacking the technical knowledge to
write the necessary low-level code. Writing low-level code is not necessary
when using the popular Brian simulator, which provides a framework to generate
efficient &lt;span class="caps"&gt;CPU&lt;/span&gt; code from high-level model definitions in Python. Here, we
present Brian2CUDA, an open-source software that extends the Brian simulator
with a &lt;span class="caps"&gt;GPU&lt;/span&gt; backend. Our implementation generates efficient code for the
numerical integration of neuronal states and for the propagation of synaptic
events on GPUs, making use of their massively parallel arithmetic capabilities.
We benchmark the performance improvements of our software for several model
types and find that it can accelerate simulations by up to three orders of
magnitude compared to Brian&amp;#8217;s &lt;span class="caps"&gt;CPU&lt;/span&gt; backend. Currently, Brian2CUDA is the only
package that supports Brian&amp;#8217;s full feature set on GPUs, including arbitrary
neuron and synapse models, plasticity rules, and heterogeneous delays. When
comparing its performance with Brian2GeNN, another &lt;span class="caps"&gt;GPU&lt;/span&gt;-based backend for the
Brian simulator with fewer features, we find that Brian2CUDA gives comparable
speedups, while being typically slower for small and faster for large networks.
By combining the flexibility of the Brian simulator with the simulation speed
of GPUs, Brian2CUDA enables researchers to efficiently simulate spiking neural
networks with minimal effort and thereby makes the advancements of &lt;span class="caps"&gt;GPU&lt;/span&gt;
computing available to a larger audience of&amp;nbsp;neuroscientists.&lt;/p&gt;
&lt;p&gt;References:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Publication: &lt;a class="reference external" href="https://www.frontiersin.org/articles/10.3389/fninf.2022.883700/abstract"&gt;Brian2CUDA: flexible and efficient simulation of spiking neural network models on GPUs (Frontiers in&amp;nbsp;Neuroinformatics)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Documentation: &lt;a class="reference external" href="https://brian2cuda.readthedocs.io/en/latest/"&gt;https://brian2cuda.readthedocs.io/en/latest/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Source code: &lt;a class="reference external" href="https://github.com/brian-team/brian2cuda"&gt;https://github.com/brian-team/brian2cuda&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content><category term="Events"></category><category term="Brian2CUDA"></category><category term="Dev session"></category><category term="GPU"></category><category term="Python"></category><category term="C++"></category><category term="CUDA"></category><category term="Nvidia"></category><category term="Simulation"></category><category term="Code generation"></category></entry></feed>